
@misc{kaggle:survey,
  title={State of Data Science and Machine Learning 2019},
  url={https://www.kaggle.com/kaggle-survey-2019},
  journal={Kaggle},
  year={2019},
  author = {Kaggle},
  note={\url{https://www.kaggle.com/kaggle-survey-2019}}
}

% precision recall vs AUC
@article{saito2015precision,
  title={The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets},
  author={Saito, Takaya and Rehmsmeier, Marc},
  journal={PloS one},
  volume={10},
  number={3},
  pages={e0118432},
  year={2015},
  publisher={Public Library of Science}
}
% multi-stage hyperparameter tuning
@inproceedings{wang-etal-2015-efficient,
    title = "Efficient Hyper-parameter Optimization for {NLP} Applications",
    author = "Wang, Lidan  and
      Feng, Minwei  and
      Zhou, Bowen  and
      Xiang, Bing  and
      Mahadevan, Sridhar",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1253",
    doi = "10.18653/v1/D15-1253",
    pages = "2112--2117",
}

% kruskal wallis assumptions
@book{mcdonald2009handbook,
  title={Handbook of biological statistics},
  author={McDonald, John H},
  volume={2},
  year={2009}
}

% levene test
@article{brown1974robust,
  title={Robust tests for the equality of variances},
  author={Brown, Morton B and Forsythe, Alan B},
  journal={Journal of the American Statistical Association},
  volume={69},
  number={346},
  pages={364--367},
  year={1974},
  publisher={Taylor \& Francis}
}

% a more detailed description of the paper below
@inproceedings{van2018hyperparameter,
  title={Hyperparameter importance across datasets},
  author={van Rijn, Jan N and Hutter, Frank},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2367--2376},
  year={2018},
  organization={ACM}
}

% functional ANOVA, multiple datasets
@inproceedings{van2017empirical,
  title={An Empirical Study of Hyperparameter Importance Across Datasets.},
  author={van Rijn, Jan N and Hutter, Frank},
  year={2017}
}

% functional ANOVA approach to assess hyperparam importance - single datasets
@inproceedings{hoos201x4efficient,
  title={An efficient approach for assessing hyperparameter importance},
  author={Hoos, Holger and Ca, UBC and Leyton-Brown, Kevin},
  booktitle={International conference on machine learning},
  pages={754--762},
  year={2014}
}

% montgomery analysis
@book{montgomery2017design,
  title={Design and analysis of experiments},
  author={Montgomery, Douglas C},
  year={2017},
  publisher={John wiley \& sons}
}

% t-sne dataset
@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}


@article{mullner2011modern,
  title={Modern hierarchical, agglomerative clustering algorithms},
  author={M{\"u}llner, Daniel},
  journal={arXiv preprint arXiv:1109.2378},
  year={2011}
}

% kr-kp dataset
@misc {shapiro1987structured,
  author = "A D Shapiro",
  title = "Structured induction in expert systems",
  organization = "Turing Institute Press in association with",
  year = "1987",
}


%how lightgbm deals with categorical features
@article{fisher1958grouping,
  title={On grouping for maximum homogeneity},
  author={Fisher, Walter D},
  journal={Journal of the American statistical Association},
  volume={53},
  number={284},
  pages={789--798},
  year={1958},
  publisher={Taylor \& Francis}
}


% workshop catboost paper - 2018
@article{dorogush2018catboost,
  title={CatBoost: gradient boosting with categorical features support},
  author={Dorogush, Anna Veronika and Ershov, Vasily and Gulin, Andrey},
  journal={arXiv preprint arXiv:1810.11363},
  year={2018}
}
% catboost paper - 2018
@inproceedings{prokhorenkova2018catboost,
  title={CatBoost: unbiased boosting with categorical features},
  author={Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6638--6648},
  year={2018}
}

% a paper which used openML for benchmark (logreg & random forest)
@article{couronne2018random,
  title={Random forest versus logistic regression: a large-scale benchmark experiment},
  author={Couronn{\'e}, Raphael and Probst, Philipp and Boulesteix, Anne-Laure},
  journal={BMC bioinformatics},
  volume={19},
  number={1},
  pages={270},
  year={2018},
  publisher={BioMed Central}
}


% OpenML paper
@article{Vanschoren:2014:ONS:2641190.2641198,
 author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
 title = {OpenML: Networked Science in Machine Learning},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {December 2013},
 volume = {15},
 number = {2},
 month = jun,
 year = {2014},
 issn = {1931-0145},
 pages = {49--60},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2641190.2641198},
 doi = {10.1145/2641190.2641198},
 acmid = {2641198},
 publisher = {ACM},
} 

% Pingouin citation
@ARTICLE{Vallat2018,
  title    = "Pingouin: statistics in Python",
  author   = "Vallat, Raphael",
  journal  = "The Journal of Open Source Software",
  volume   =  3,
  number   =  31,
  pages    = "1026",
  month    =  nov,
  year     =  2018
}

% scikit-posthoc citation
@ARTICLE{Terpilowski2019,
  title    = {scikit-posthocs: Pairwise multiple comparison tests in Python},
  author   = {Terpilowski, Maksim},
  journal  = {The Journal of Open Source Software},
  volume   = {4},
  number   = {36},
  pages    = {1169},
  year     = {2019},
  doi      = {10.21105/joss.01169}
}

% brier score decomposition
@article{murphy1973new,
  title={A new vector partition of the probability score},
  author={Murphy, Allan H},
  journal={Journal of applied Meteorology},
  volume={12},
  number={4},
  pages={595--600},
  year={1973}
}


% brier score
@article{rufibach2010use,
  title={Use of Brier score to assess binary predictions},
  author={Rufibach, Kaspar},
  journal={Journal of clinical epidemiology},
  volume={63},
  number={8},
  pages={938--939},
  year={2010},
  publisher={Elsevier}
}


% ROC and AUC
@article{BROWN200624,
title = "Receiver operating characteristics curves and related decision measures: A tutorial",
journal = "Chemometrics and Intelligent Laboratory Systems",
volume = "80",
number = "1",
pages = "24 - 38",
year = "2006",
issn = "0169-7439",
doi = "https://doi.org/10.1016/j.chemolab.2005.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0169743905000766",
author = "Christopher D. Brown and Herbert T. Davis",
keywords = "Receiver operator characteristic, ROC curve, Classification, Likelihood ratio, Decision theory, Bayesian, Cost, Limit of detection",
}

@misc{lightgbmparams,
title={Parameters Tuning},
url={https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html},
journal={Parameters Tuning - LightGBM documentation},
author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
year={2017}
}


% LightGBM paper
@inproceedings{ke2017lightgbm,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  pages={3146--3154},
  year={2017}
}

%XGBOOST learningSYS conference 2015
@article{chen2015xgboost,
  title={XGBoost: Reliable Large-scale Tree Boosting System},
  author={Chen, Tianqi and Guestrin, Carlos},
  year={2015}
}


% XGBOOST paper
@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016},
  organization={ACM}
}


% article about hyperparameter tuning for decision trees
@article{mantovani2018empirical,
  title={An empirical study on hyperparameter tuning of decision trees},
  author={Mantovani, Rafael Gomes and Horv{\'a}th, Tom{\'a}{\v{s}} and Cerri, Ricardo and Junior, Sylvio Barbon and Vanschoren, Joaquin and de Carvalho, Andr{\'e} Carlos Ponce de and Ferreira, Leon},
  journal={arXiv preprint arXiv:1812.02207},
  year={2018}
}

% Hyperopt
@inproceedings{bergstra2013hyperopt,
  title={Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms},
  author={Bergstra, James and Yamins, Dan and Cox, David D},
  year={2013},
  organization={Citeseer}
}

% Microsoft -  Soft. Eng. for Machine Learning
@InProceedings{amershi2019software,
author = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Rob and Gall, Harald and Kamar, Ece and Nagappan, Nachi and Nushi, Besmira and Zimmermann, Tom},
title = {Software Engineering for Machine Learning: A Case Study},
booktitle = {International Conference on Software Engineering (ICSE 2019) - Software Engineering in Practice track},
year = {2019},
month = {May},
publisher = {IEEE Computer Society},
url = {https://www.microsoft.com/en-us/research/publication/software-engineering-for-machine-learning-a-case-study/},
}

% Applied predictive modeling
@book{kuhn2013applied,
  title={Applied predictive modeling},
  author={Kuhn, Max and Johnson, Kjell},
  volume={26},
  year={2013},
  publisher={Springer}
}

%% Hyperparameter importance article
@article{probst2018tunability,
  title={Tunability: Importance of hyperparameters of machine learning algorithms},
  author={Probst, Philipp and Bischl, Bernd and Boulesteix, Anne-Laure},
  journal={arXiv preprint arXiv:1802.09596},
  year={2018}
}

%% AIMA
@book{aima:2010,
 author = {Russell, Stuart J. and Norvig, Peter},
 title = {Artificial Intelligence: A Modern Approach},
 year = {2010},
 isbn = {0137903952},
 edition = {Third},
 publisher = {Prentice Hall},
} 

%% Elements of statistical learning
@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author={Hastie, T. and Tibshirani, R. and Friedman, J.H.},
  isbn={9780387848846},
  lccn={2008941148},
  series={Springer series in statistics},
  url={https://books.google.com.br/books?id=eBSgoAEACAAJ},
  year={2009},
  publisher={Springer}
}

%% Deep learning: Goodfellow
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

%% Como citar uma URL
@Misc{explai:19,
title={How to explain gradient boosting},
journal={explained.ai}, 
author={Terence Parr and Jeremy Howard},
year     = {2018},
note= {\url{https://explained.ai/gradient-boosting/index.html}}
}

%% Gradient descent algorithms comparison
@article{Ruder2016AnOO,
  title={An overview of gradient descent optimization algorithms},
  author={Sebastian Ruder},
  journal={CoRR},
  year={2016},
  volume={abs/1609.04747},
  note= {\url{https://arxiv.org/abs/1609.04747}}
}
%% Friedman: GBM paper
@article{gbmdef,
    author = {Jerome H. Friedman},
    title = {Greedy Function Approximation: A Gradient Boosting Machine},
    journal = {Annals of Statistics},
    year = {2000},
    volume = {29},
    pages = {1189--1232}
}

%% Friedman, about additive models
@article{doi:10.1080/01621459.1981.10477729,
author = { Jerome H.   Friedman  and  Werner   Stuetzle },
title = {Projection Pursuit Regression},
journal = {Journal of the American Statistical Association},
volume = {76},
number = {376},
pages = {817-823},
year  = {1981},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1981.10477729},
note= {\url{https://www.tandfonline.com/doi/abs/10.1080/01621459.1981.10477729}}
}

% Li - gradient boosting benchmarks
@article{li2012robust,
  title={Robust logitboost and adaptive base class (abc) logitboost},
  author={Li, Ping},
  journal={arXiv preprint arXiv:1203.3491},
  year={2012}
}

%% [IMAGE] adaboost 
@Misc{adaboost:brendan,
author = {Marsh, Brendan},
year = {2016},
month = {09},
pages = {},
title = {Multivariate Analysis of the Vector Boson Fusion Higgs Boson}
}

@article{Schapire:1999:BIB:1624312.1624417,
 author = {Schapire, Robert E.},
 title = {A Brief Introduction to Boosting},
 journal = {Proceedings of the 16th International Joint Conference on Artificial Intelligence - Volume 2},
 series = {IJCAI'99},
 year = {1999},
 location = {Stockholm, Sweden},
 pages = {1401--1406},
 numpages = {6},
 note= {\url{http://dl.acm.org/citation.cfm?id=1624312.1624417}},
 acmid = {1624417},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 
